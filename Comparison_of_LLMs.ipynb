{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\harshu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain huggingface_hub openai==0.27.2 google-search-results tiktoken cohere google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "OPENAI_API_VERSION = os.environ['AZURE_API_VERSION']\n",
    "OPENAI_API_BASE = os.environ['AZURE_OPENAI_BASE']\n",
    "OPENAI_API_KEY = os.environ['AZURE_OPENAI_KEY']\n",
    "DEPLOYMENT_NAME = os.environ['DEPLOYMENT_NAME']\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "# os.environ[\"COHERE_API_KEY\"] = getpass(prompt = \"Enter you Cohere API KEY\")\n",
    "os.environ[\"COHERE_API_KEY\"] = os.environ[\"COHERE_KEY\"]\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.environ[\"HUGGINGFACE_TOKEN\"]\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ[\"PALM_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "openai.api_base = os.environ[\"AZURE_OPENAI_BASE\"]\n",
    "openai.api_version = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchainNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.0.309\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\Harshu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: aiohttp, anyio, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_temperature = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.environ[\"HUGGINGFACE_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Harshu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "flan_20B = HuggingFaceHub(\n",
    "    repo_id = \"google/flan-ul2\",\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : overall_temperature,\n",
    "        \"max_new_tokens\" : 200\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_t5xxl = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", \n",
    "                         model_kwargs={\"temperature\":overall_temperature, \n",
    "                                       \"max_new_tokens\":200}\n",
    "                         ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt_j6B = HuggingFaceHub(repo_id=\"EleutherAI/gpt-j-6B\", \n",
    "                         model_kwargs={\"temperature\":overall_temperature, \n",
    "                                       \"max_new_tokens\":100}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up Google Palm model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm = GooglePalm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up Azure OpenAI model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_TYPE'] = OPENAI_API_TYPE\n",
    "os.environ['OPENAI_API_VERSION'] = OPENAI_API_VERSION\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['OPENAI_API_BASE'] = OPENAI_API_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI, OpenAI, OpenAIChat\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "azure_openai = llm = AzureOpenAI(\n",
    "    deployment_name=\"Developer-35-turbo-instruct\",\n",
    "    model_name=\"gpt-35-turbo-instruct\",\n",
    ")\n",
    "\n",
    "chatGPT_turbo = OpenAIChat(\n",
    "             engine=\"Developer-35-turbo\",\n",
    "             model_name=\"gpt-35-turbo\",\n",
    "             temperature=overall_temperature, \n",
    "             max_tokens = 256,\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up Cohere models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_command_x1 = Cohere(\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"],\n",
    "    model = \"command-xlarge\",\n",
    "    temperature = overall_temperature,\n",
    "    max_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_command_x1_nightly = Cohere(\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"],\n",
    "    model = \"command-xlarge-nightly\",\n",
    "    temperature = overall_temperature,\n",
    "    max_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup a comparison lab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template = template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = ModelLaboratory.from_llms([\n",
    "    azure_openai, \n",
    "    chatGPT_turbo,\n",
    "    palm,\n",
    "    # gpt_j6B, \n",
    "    flan_20B,\n",
    "    flan_t5xxl, \n",
    "    cohere_command_x1, \n",
    "    cohere_command_x1_nightly\n",
    "], prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "What is the opposite of up?\n",
      "\n",
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'Developer-35-turbo-instruct', 'model_name': 'gpt-35-turbo-instruct', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[36;1m\u001b[1;3m The opposite of up is down. However, this is not the only opposite. We can also say the opposite of up is down, or the opposite of up is horizontal. This is because up and down are directions, while horizontal is a position. Another possible opposite is top, as in the top of a mountain, compared to the bottom or base of the mountain. Similarly, we could say the opposite of up is low, as in a low point compared to a high point. Ultimately, the opposite of up can have multiple interpretations and is dependent on the context in which it is used.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-35-turbo', 'engine': 'Developer-35-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[33;1m\u001b[1;3mThe opposite of up is down.\u001b[0m\n",
      "\n",
      "\u001b[1mGooglePalm\u001b[0m\n",
      "Params: {}\n",
      "\u001b[38;5;200m\u001b[1;3mUp is opposite of down. down\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mDown is the opposite of up. Up is the action of rising. Down is the action of sinking. The answer: down.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[31;1m\u001b[1;3mDown is the opposite of up. Down is the opposite of up. Down is the opposite of up. The answer: down.\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge', 'max_tokens': 1000, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[36;1m\u001b[1;3m The opposite of up is down.\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge-nightly', 'max_tokens': 1000, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[33;1m\u001b[1;3m The opposite of up could refer to a direction that is opposite to the upward direction. In physics, the opposite direction to upward would be downward. For example, if you are standing on the ground, moving up would mean moving towards the sky, while moving down would mean moving towards the ground. Therefore, the opposite of up is down. \n",
      "\n",
      "It is important to note that the concept of up and down is relative and depends on the reference point being used. For example, if you are in an elevator, moving down would mean moving towards the ground when the elevator is going up. However, when the elevator is going down, moving down would mean moving towards the roof of the elevator. \n",
      "\n",
      "In everyday language, people might also use other terms to describe the opposite of up, such as down, backward, or in the negative direction. It depends on the context and the frame of reference being used. \n",
      "\n",
      "Would you like to know more about the opposite directions? \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare(\"What is the opposite of up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?\n",
      "\n",
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'Developer-35-turbo-instruct', 'model_name': 'gpt-35-turbo-instruct', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[36;1m\u001b[1;3m \n",
      "\n",
      "Step 1: The cafeteria had 23 apples.\n",
      "This means that initially, the cafeteria had 23 apples.\n",
      "\n",
      "Step 2: If they used 20 for lunch,\n",
      "This means that out of the 23 apples, 20 were used for lunch.\n",
      "\n",
      "Step 3: and bought 6 more,\n",
      "This means that in addition to the 3 apples left, the cafeteria bought 6 more apples.\n",
      "\n",
      "Step 4: how many apples do they have?\n",
      "To find the total number of apples the cafeteria has now, we need to add the 3 apples left with the 6 apples bought, which gives us a total of 9 apples.\n",
      "\n",
      "Step 5: Therefore, the cafeteria now has 9 apples. \n",
      "We can conclude that after using 20 apples for lunch and buying 6 more, the cafeteria now has 9 apples remaining.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-35-turbo', 'engine': 'Developer-35-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[33;1m\u001b[1;3mStep 1: The cafeteria had 23 apples.\n",
      "Step 2: They used 20 apples for lunch.\n",
      "Step 3: Subtracting 20 from 23, we find that they have 3 apples left.\n",
      "Step 4: They bought 6 more apples.\n",
      "Step 5: Adding 6 to the 3 apples they had left, we find that they now have 9 apples.\u001b[0m\n",
      "\n",
      "\u001b[1mGooglePalm\u001b[0m\n",
      "Params: {}\n",
      "\u001b[38;5;200m\u001b[1;3m23 - 20 = 3. 3 + 6 = 9. 9 apples.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mThe cafeteria has 23 - 20 = 3 apples left. They have 3 + 6 = 9 apples. So the answer is 9.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[31;1m\u001b[1;3mThe cafeteria had 23 - 20 = 3 apples left after lunch. They bought 6 + 3 = 7 apples. The cafeteria has 7 - 3 = 2 apples.\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge', 'max_tokens': 1000, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[36;1m\u001b[1;3m After using 20 apples for lunch, the cafeteria now has 23 - 20 = 3 apples. The cafeteria then bought 6 more apples, so they now have 3 + 6 = 9 apples.\n",
      "So, the answer is 9.\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge-nightly', 'max_tokens': 1000, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[33;1m\u001b[1;3m They used 20 apples for lunch, so they have 23 - 20 = 3 apples left.\n",
      "They then bought 6 more apples, for a total of 3 + 6 = 9 apples.\n",
      "The cafeteria therefore has 9 apples.\n",
      "So, the answer is 9.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare(\"Answer the following question by reasoning step by step. The cafeteria had 23 apples. \\\n",
    "If they used 20 for lunch, and bought 6 more, how many apple do they have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "How to make pizza?\n",
      "\n",
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'Developer-35-turbo-instruct', 'model_name': 'gpt-35-turbo-instruct', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[36;1m\u001b[1;3m First, gather all the necessary ingredients: pizza dough, tomato sauce, cheese, toppings of your choice (such as pepperoni, vegetables, or pineapple), and any desired herbs or seasonings.\n",
      "\n",
      "Step 1: Preheat your oven to 450 degrees Fahrenheit (232 degrees Celsius).\n",
      "\n",
      "Step 2: Roll out your pizza dough on a floured surface to the desired thickness. You can also use a pre-made pizza crust if you prefer.\n",
      "\n",
      "Step 3: Spread a thin layer of tomato sauce onto the dough, leaving about half an inch around the edge.\n",
      "\n",
      "Step 4: Sprinkle your desired amount of cheese on top of the sauce. You can use any kind of cheese, such as mozzarella, cheddar, or a blend of cheeses.\n",
      "\n",
      "Step 5: Add your desired toppings on top of the cheese. Be creative and choose toppings that you enjoy!\n",
      "\n",
      "Step 6: Optional: Sprinkle herbs or seasonings, such as oregano or garlic powder, on top of the pizza for added flavor.\n",
      "\n",
      "Step 7: Carefully transfer the pizza onto a baking sheet or pizza stone and place it in the preheated oven.\n",
      "\n",
      "Step 8: Bake for 12-15 minutes, or until the crust is golden brown and the cheese is melted\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-35-turbo', 'engine': 'Developer-35-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[33;1m\u001b[1;3m1. Start by making the pizza dough. In a large mixing bowl, combine 2 ¼ teaspoons of active dry yeast, 1 teaspoon of sugar, and 1 ½ cups of warm water. Let it sit for about 5 minutes until the yeast becomes foamy.\n",
      "\n",
      "2. Gradually add 3 ½ cups of all-purpose flour and 2 teaspoons of salt to the yeast mixture. Stir until a dough forms.\n",
      "\n",
      "3. Transfer the dough onto a floured surface and knead it for about 5-7 minutes until it becomes smooth and elastic. If the dough is too sticky, add a little more flour.\n",
      "\n",
      "4. Place the dough in a greased bowl, cover it with a clean kitchen towel, and let it rise in a warm place for about 1-2 hours or until it doubles in size.\n",
      "\n",
      "5. While the dough is rising, you can prepare the pizza sauce. In a saucepan, heat 2 tablespoons of olive oil over medium heat. Add 3 cloves of minced garlic and sauté for about 1 minute until fragrant. Then, add a 28-ounce can of crushed tomatoes, 1 teaspoon of dried oregano, 1 teaspoon of dried basil, 1 teaspoon of sugar,\u001b[0m\n",
      "\n",
      "\u001b[1mGooglePalm\u001b[0m\n",
      "Params: {}\n",
      "\u001b[38;5;200m\u001b[1;3m1. Preheat oven to 450 degrees F (230 degrees C).\n",
      "2. Prepare the dough according to package directions.\n",
      "3. Roll out the dough into a 12-inch circle.\n",
      "4. Place the dough on a greased baking sheet.\n",
      "5. Spread the pizza sauce over the dough.\n",
      "6. Add your desired toppings.\n",
      "7. Bake for 10-12 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\n",
      "8. Let cool for a few minutes before slicing and serving.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mMake the dough. Stretch it out and put it in a pan. Add the sauce and cheese. Bake it.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[31;1m\u001b[1;3mTo make pizza, you need to make a pizza dough. Then, you need to put the pizza sauce on the pizza dough. Then, you need to put the cheese on the pizza. Then, you need to put the toppings on the pizza.\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge', 'max_tokens': 500, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[36;1m\u001b[1;3m To make pizza, you'll need pizza dough, tomato sauce, cheese, and your chosen toppings. First, preheat your oven to 525 degrees Fahrenheit. Then, roll out your pizza dough on a lightly floured surface until it forms a 12-inch circle. Place the dough on a baking sheet or pizza pan. Next, spread the tomato sauce over the dough, leaving a 1-inch border around the edge. Sprinkle the cheese over the sauce. Then add your desired toppings. Bake the pizza for 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly. Enjoy!\u001b[0m\n",
      "\n",
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'model': 'command-xlarge-nightly', 'max_tokens': 500, 'temperature': 0.1, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n",
      "\u001b[33;1m\u001b[1;3m To make pizza, you will need the following ingredients: dough, tomato sauce, cheese, and your desired toppings. Here is a general guide on how to make pizza:\n",
      "\n",
      "1. Preheat the oven to 475°F (246°C). This will give your pizza the crispy crust. \n",
      "\n",
      "2. Prepare your pizza dough. You can buy pre-made pizza dough from most grocery stores, or you can make your own from scratch. If using store-bought dough, follow the package instructions for preparing it. If making your own dough, you will need flour, yeast, salt, and warm water. Mix the dry ingredients together and then slowly add the warm water until the dough can be shaped into a ball. Knead the dough on a floured surface for 5-10 minutes, then place it in a greased bowl and cover it with a damp cloth. Let the dough rise in a warm place for 30 minutes.\n",
      "\n",
      "3. While the dough is rising, prepare your tomato sauce. You can use store-bought pizza sauce or make your own by mixing crushed tomatoes, garlic, olive oil, and Italian seasoning in a bowl. \n",
      "\n",
      "4. Once the dough has risen, divide it into two equal pieces and shape them into rounds. You can use a rolling pin to roll out the dough into your desired thickness and shape. \n",
      "\n",
      "5. Place your rolled-out dough onto a baking sheet or pizza pan that has been greased or lined with parchment paper. \n",
      "\n",
      "6. Spread a thin layer of tomato sauce over the dough, leaving about a 1-inch border around the edge. \n",
      "\n",
      "7. Add your desired toppings to the pizza. Some common toppings include mozzarella cheese, pepperoni, mushrooms, onions, peppers, and olives. You can also add more spices at this point, such as garlic powder, oregano, or basil. \n",
      "\n",
      "8. Bake the pizza in the preheated oven for 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly. \n",
      "\n",
      "9. Remove the pizza from the oven and let it cool for a few minutes before slicing and serving. \n",
      "\n",
      "And there you have it! Your very own pizza, fresh from the oven. Feel free to get creative with your toppings and find your favorite combinations. \n",
      "\n",
      "Would you like to know any other specific steps to make pizza? \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare(\"How to make pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
